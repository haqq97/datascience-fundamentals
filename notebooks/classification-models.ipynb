{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4761d42f",
   "metadata": {},
   "source": [
    "### Goal: Compare different classification models in the task to predict whether a user will purchase based on age and estimated salary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6f88d114",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification Model Comparison Results:\n",
      "\n",
      "                 Model                                               Params  Accuracy  Precision   Recall  F1 Score  ROC AUC  Train Time (s)  Predict Time (s)\n",
      "           Naive Bayes                                                   {}    0.9375   0.925926 0.892857  0.909091 0.986951        0.000325          0.000113\n",
      "   K-Nearest Neighbors                                   {'n_neighbors': 7}    0.9375   0.870968 0.964286  0.915254 0.972871        0.000319          0.001940\n",
      "   K-Nearest Neighbors                                   {'n_neighbors': 9}    0.9375   0.870968 0.964286  0.915254 0.970810        0.000295          0.001857\n",
      "Support Vector Machine     {'C': 100, 'kernel': 'rbf', 'probability': True}    0.9375   0.870968 0.964286  0.915254 0.947115        0.007400          0.000329\n",
      "Support Vector Machine     {'C': 0.1, 'kernel': 'rbf', 'probability': True}    0.9250   0.866667 0.928571  0.896552 0.980082        0.004689          0.000546\n",
      "   K-Nearest Neighbors                                   {'n_neighbors': 3}    0.9250   0.866667 0.928571  0.896552 0.971154        0.000330          0.001647\n",
      "Support Vector Machine       {'C': 1, 'kernel': 'rbf', 'probability': True}    0.9250   0.843750 0.964286  0.900000 0.969780        0.003291          0.000357\n",
      "Support Vector Machine      {'C': 10, 'kernel': 'rbf', 'probability': True}    0.9250   0.843750 0.964286  0.900000 0.961538        0.004049          0.000354\n",
      "   K-Nearest Neighbors                                   {'n_neighbors': 5}    0.9125   0.862069 0.892857  0.877193 0.974931        0.000376          0.001868\n",
      "         Random Forest                                 {'n_estimators': 50}    0.9125   0.818182 0.964286  0.885246 0.953297        0.030173          0.001852\n",
      "         Random Forest                                {'n_estimators': 200}    0.9125   0.818182 0.964286  0.885246 0.948146        0.117107          0.006456\n",
      "         Decision Tree                                     {'max_depth': 5}    0.9000   0.833333 0.892857  0.862069 0.962569        0.000444          0.000097\n",
      "         Random Forest                                {'n_estimators': 100}    0.9000   0.812500 0.928571  0.866667 0.953984        0.058936          0.003372\n",
      "   Logistic Regression                                            {'C': 10}    0.8875   0.913043 0.750000  0.823529 0.968407        0.001016          0.000107\n",
      "   Logistic Regression                                           {'C': 100}    0.8875   0.913043 0.750000  0.823529 0.968407        0.000865          0.000090\n",
      "   Logistic Regression                                           {'C': 0.1}    0.8750   0.950000 0.678571  0.791667 0.968407        0.000907          0.000103\n",
      "Support Vector Machine  {'C': 0.1, 'kernel': 'linear', 'probability': True}    0.8750   0.950000 0.678571  0.791667 0.959478        0.002689          0.000217\n",
      "   Logistic Regression                                             {'C': 1}    0.8625   0.904762 0.678571  0.775510 0.968407        0.000843          0.000099\n",
      "Support Vector Machine  {'C': 100, 'kernel': 'linear', 'probability': True}    0.8625   0.904762 0.678571  0.775510 0.961538        0.022410          0.000241\n",
      "Support Vector Machine    {'C': 1, 'kernel': 'linear', 'probability': True}    0.8625   0.904762 0.678571  0.775510 0.960165        0.003010          0.000208\n",
      "Support Vector Machine   {'C': 10, 'kernel': 'linear', 'probability': True}    0.8625   0.904762 0.678571  0.775510 0.960165        0.005699          0.000260\n",
      "         Random Forest                                 {'n_estimators': 10}    0.8625   0.793103 0.821429  0.807018 0.922047        0.009603          0.000541\n",
      "         Decision Tree                                    {'max_depth': 10}    0.8500   0.807692 0.750000  0.777778 0.837912        0.000484          0.000096\n",
      "         Decision Tree                                  {'max_depth': None}    0.8375   0.777778 0.750000  0.763636 0.817308        0.000562          0.000110\n",
      "         Decision Tree                                    {'max_depth': 15}    0.8375   0.777778 0.750000  0.763636 0.817308        0.000491          0.000103\n",
      "         Decision Tree                                    {'max_depth': 20}    0.8375   0.777778 0.750000  0.763636 0.817308        0.000467          0.000092\n",
      "Support Vector Machine {'C': 0.01, 'kernel': 'linear', 'probability': True}    0.8250   1.000000 0.500000  0.666667 0.959478        0.003520          0.000303\n",
      "   K-Nearest Neighbors                                   {'n_neighbors': 1}    0.8250   0.769231 0.714286  0.740741 0.799451        0.000370          0.002120\n",
      "   Logistic Regression                                          {'C': 0.01}    0.8125   1.000000 0.464286  0.634146 0.964973        0.001237          0.000138\n",
      "Support Vector Machine    {'C': 0.01, 'kernel': 'rbf', 'probability': True}    0.6500   0.000000 0.000000  0.000000 0.980769        0.006050          0.000686\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import time\n",
    "from sklearn.model_selection import train_test_split, ParameterGrid\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score,\n",
    "    roc_auc_score, confusion_matrix, classification_report, roc_curve\n",
    ")\n",
    "\n",
    "# Load dataset\n",
    "data = pd.read_csv('../datasets/social-network-ads.csv')\n",
    "\n",
    "# split into features and target\n",
    "X = data.iloc[:, :-1].values  # Features: Age, EstimatedSalary\n",
    "y = data.iloc[:, -1].values  # Target: Purchased\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)    \n",
    "\n",
    "# Prepare scaled versions for models that need it - Logistic Regression, SVM, KNN\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Model configs\n",
    "# What each hyperparameter means:\n",
    "# - C: Inverse of regularization strength; smaller values specify stronger regularization.\n",
    "# - max_depth: Maximum depth of the tree; controls overfitting.\n",
    "# - n_estimators: Number of trees in the forest; more trees can lead to better performance but also longer training time.\n",
    "# - n_neighbors: Number of neighbors to use for KNN. More neighbors can smooth out noise but may also miss local patterns.\n",
    "# - kernel: Specifies the kernel type to be used in SVM; 'linear' is a linear kernel, 'rbf' is a radial basis function kernel.\n",
    "# - probability: If True, enables probability estimates for SVM, which is useful for ROC AUC calculation.\n",
    "model_configs = [\n",
    "    {\n",
    "        'name': 'Logistic Regression',\n",
    "        'model': LogisticRegression,\n",
    "        'params': {'C': [0.01, 0.1, 1, 10, 100]},\n",
    "        'use_scaling': True\n",
    "    },\n",
    "    {\n",
    "        'name': 'Decision Tree',\n",
    "        'model': DecisionTreeClassifier,\n",
    "        'params': {'max_depth': [None, 5, 10, 15, 20]},\n",
    "        'use_scaling': False\n",
    "    },\n",
    "    {\n",
    "        'name': 'Random Forest',\n",
    "        'model': RandomForestClassifier,\n",
    "        'params': {'n_estimators': [10, 50, 100, 200]},\n",
    "        'use_scaling': False\n",
    "    },\n",
    "    {\n",
    "        'name': 'K-Nearest Neighbors',\n",
    "        'model': KNeighborsClassifier,\n",
    "        'params': {'n_neighbors': [1, 3, 5, 7, 9]},\n",
    "        'use_scaling': True\n",
    "    },\n",
    "    {\n",
    "        'name': 'Support Vector Machine',\n",
    "        'model': SVC,\n",
    "        'params': {'C': [0.01, 0.1, 1, 10, 100], 'kernel': ['linear', 'rbf'], 'probability': [True]},\n",
    "        'use_scaling': True\n",
    "    },\n",
    "    {\n",
    "        'name': 'Naive Bayes',\n",
    "        'model': GaussianNB,\n",
    "        'params': {},\n",
    "        'use_scaling': True\n",
    "    }\n",
    "]\n",
    "\n",
    "results = []\n",
    "\n",
    "for config in model_configs:\n",
    "    param_grid = list(ParameterGrid(config['params'])) if config['params'] else [{}]\n",
    "    for params in param_grid:\n",
    "        # Prepare data\n",
    "        Xtr = X_train_scaled if config['use_scaling'] else X_train\n",
    "        Xte = X_test_scaled if config['use_scaling'] else X_test\n",
    "\n",
    "        # Build and train model\n",
    "        model = config['model'](**params)\n",
    "        start_train = time.time()\n",
    "        model.fit(Xtr, y_train)\n",
    "        train_time = time.time() - start_train\n",
    "\n",
    "        # Predict\n",
    "        start_pred = time.time()\n",
    "        y_pred = model.predict(Xte)\n",
    "        pred_time = time.time() - start_pred\n",
    "\n",
    "        # Probabilities for ROC AUC\n",
    "        if hasattr(model, \"predict_proba\"):\n",
    "            y_proba = model.predict_proba(Xte)[:, 1]\n",
    "        elif hasattr(model, \"decision_function\"):\n",
    "            # For SVM with probability=False\n",
    "            y_proba = model.decision_function(Xte)\n",
    "            y_proba = (y_proba - y_proba.min()) / (y_proba.max() - y_proba.min())  # scale to [0,1]\n",
    "        else:\n",
    "            y_proba = y_pred  # fallback\n",
    "\n",
    "        # Metrics\n",
    "        acc = accuracy_score(y_test, y_pred)\n",
    "        prec = precision_score(y_test, y_pred, zero_division=0)\n",
    "        rec = recall_score(y_test, y_pred, zero_division=0)\n",
    "        f1 = f1_score(y_test, y_pred, zero_division=0)\n",
    "        try:\n",
    "            auc = roc_auc_score(y_test, y_proba)\n",
    "        except:\n",
    "            auc = np.nan\n",
    "        cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "        # Store results\n",
    "        results.append({\n",
    "            'Model': config['name'],\n",
    "            'Params': params,\n",
    "            'Accuracy': acc,\n",
    "            'Precision': prec,\n",
    "            'Recall': rec,\n",
    "            'F1 Score': f1,\n",
    "            'ROC AUC': auc,\n",
    "            'Train Time (s)': train_time,\n",
    "            'Predict Time (s)': pred_time,\n",
    "            'Confusion Matrix': cm\n",
    "        })\n",
    "\n",
    "# Results DataFrame\n",
    "results_df = pd.DataFrame(results)\n",
    "# Show only key columns for comparison\n",
    "display_cols = ['Model', 'Params', 'Accuracy', 'Precision', 'Recall', 'F1 Score', 'ROC AUC', 'Train Time (s)', 'Predict Time (s)']\n",
    "\n",
    "# Which should you sort by?\n",
    "# If your classes are balanced and both errors are equally important:\n",
    "# Sort by Accuracy or F1 Score.\n",
    "# If you care more about not missing buyers (recall):\n",
    "# Sort by Recall or F1 Score.\n",
    "# If you care more about only targeting likely buyers (precision):\n",
    "# Sort by Precision.\n",
    "# If your classes are imbalanced or you want a robust, threshold-independent metric:\n",
    "# Sort by ROC AUC (recommended in most business cases).\n",
    "\n",
    "    \n",
    "# Display results\n",
    "print(\"\\nClassification Model Comparison Results:\\n\")\n",
    "print(results_df[display_cols].sort_values(['Accuracy', 'ROC AUC'], ascending=[False, False]).to_string(index=False))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.9.6)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

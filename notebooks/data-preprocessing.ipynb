{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d0cea38f",
   "metadata": {},
   "source": [
    "### Load Dataset and EDA\n",
    "1. Load the dataset\n",
    "2. Explore the dataset (shape, head, info)\n",
    "3. Check for missing values\n",
    "4. Unique values in categorical features\n",
    "5. Target distribution\n",
    "6. Numeric feature distribution and outliers\n",
    "7. Categorical feature distribution\n",
    "8. Correlation matrix for numeric features\n",
    "9. Pairwise relationships (if applicable)\n",
    "\n",
    "Notes:\n",
    "Very large (>1 M rows) - consider sampling or “chunked” reading rather than loading everything into memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "84c9f612",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Shape: (10, 4)\n",
      "First 5 rows of the dataset:\n",
      "   Country   Age   Salary Purchased\n",
      "0   France  44.0  72000.0        No\n",
      "1    Spain  27.0  48000.0       Yes\n",
      "2  Germany  30.0  54000.0        No\n",
      "3    Spain  38.0  61000.0        No\n",
      "4  Germany  40.0      NaN       Yes\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load dataset\n",
    "dataset = pd.read_csv('../datasets/data.csv') \n",
    "print(\"Dataset Shape:\", dataset.shape)\n",
    "print(\"First 5 rows of the dataset:\")\n",
    "print(dataset.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb01bd70",
   "metadata": {},
   "source": [
    "### 2. Separating Features (X) and Target (y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fdc357f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dataset.iloc[:, :-1].values  # All rows, all columns except last\n",
    "y = dataset.iloc[:, -1].values   # All rows, last column"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a58e941a",
   "metadata": {},
   "source": [
    "### 3. Handling Missing Data\n",
    "Problem: Missing values in Age and Salary columns. </br>\n",
    "Solution: Use SimpleImputer to replace missing values with mean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "af051fc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['France' 44.0 72000.0]\n",
      " ['Spain' 27.0 48000.0]\n",
      " ['Germany' 30.0 54000.0]\n",
      " ['Spain' 38.0 61000.0]\n",
      " ['Germany' 40.0 63777.77777777778]\n",
      " ['France' 35.0 58000.0]\n",
      " ['Spain' 38.77777777777778 52000.0]\n",
      " ['France' 48.0 79000.0]\n",
      " ['Germany' 50.0 83000.0]\n",
      " ['France' 37.0 67000.0]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "imputer = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
    "imputer.fit(X[:, 1:3])   # Apply only on Age and Salary\n",
    "X[:, 1:3] = imputer.transform(X[:, 1:3])\n",
    "print(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5419c24e",
   "metadata": {},
   "source": [
    "### 4. Encoding Categorical Data\n",
    "Country (categorical) → One-Hot Encoding "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "585471ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.0 0.0 0.0 44.0 72000.0]\n",
      " [0.0 0.0 1.0 27.0 48000.0]\n",
      " [0.0 1.0 0.0 30.0 54000.0]\n",
      " [0.0 0.0 1.0 38.0 61000.0]\n",
      " [0.0 1.0 0.0 40.0 63777.77777777778]\n",
      " [1.0 0.0 0.0 35.0 58000.0]\n",
      " [0.0 0.0 1.0 38.77777777777778 52000.0]\n",
      " [1.0 0.0 0.0 48.0 79000.0]\n",
      " [0.0 1.0 0.0 50.0 83000.0]\n",
      " [1.0 0.0 0.0 37.0 67000.0]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "ct = ColumnTransformer(transformers=[('encoder', OneHotEncoder(), [0])], remainder='passthrough')\n",
    "X = ct.fit_transform(X)\n",
    "print(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e00e5357",
   "metadata": {},
   "source": [
    "Purchased (Yes/No) → Label Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e5ae0638",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 0 0 1 1 0 1 0 1]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "le = LabelEncoder()\n",
    "y = le.fit_transform(y)\n",
    "print(y)  # Yes -> 1, No -> 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a62f8aa",
   "metadata": {},
   "source": [
    "### 5. Splitting the Dataset into Training and Test Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f7ac09e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.0 0.0 0.0 35.0 58000.0]\n",
      " [1.0 0.0 0.0 44.0 72000.0]\n",
      " [1.0 0.0 0.0 48.0 79000.0]\n",
      " [0.0 1.0 0.0 30.0 54000.0]\n",
      " [1.0 0.0 0.0 37.0 67000.0]\n",
      " [0.0 1.0 0.0 40.0 63777.77777777778]\n",
      " [0.0 0.0 1.0 38.0 61000.0]\n",
      " [0.0 0.0 1.0 38.77777777777778 52000.0]]\n",
      "[[0.0 1.0 0.0 50.0 83000.0]\n",
      " [0.0 0.0 1.0 27.0 48000.0]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "print(X_train)\n",
    "print(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afdaad27",
   "metadata": {},
   "source": [
    "### 6. Feature Scaling\n",
    "Why? Age and Salary have different scales → affects models like KNN, SVM, Logistic Regression.</br>\n",
    "Note: apply feature scaling after train-test split to prevent information leakage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5ea840ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.0 0.0 0.0 -0.7529426005471072 -0.6260377781240918]\n",
      " [1.0 0.0 0.0 1.008453807952985 1.0130429500553495]\n",
      " [1.0 0.0 0.0 1.7912966561752484 1.8325833141450703]\n",
      " [0.0 1.0 0.0 -1.7314961608249362 -1.0943465576039322]\n",
      " [1.0 0.0 0.0 -0.3615211764359756 0.42765697570554906]\n",
      " [0.0 1.0 0.0 0.22561095973072184 0.05040823668012247]\n",
      " [0.0 0.0 1.0 -0.16581046438040975 -0.27480619351421154]\n",
      " [0.0 0.0 1.0 -0.013591021670525094 -1.3285009473438525]]\n",
      "[[0.0 1.0 0.0 2.1827180802863797 2.3008920936249107]\n",
      " [0.0 0.0 1.0 -2.3186282969916334 -1.7968097268236927]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "sc = StandardScaler()\n",
    "X_train[:, 3:] = sc.fit_transform(X_train[:, 3:])  # Skip one-hot columns\n",
    "X_test[:, 3:] = sc.transform(X_test[:, 3:])\n",
    "print(X_train)\n",
    "print(X_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.9.6)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
